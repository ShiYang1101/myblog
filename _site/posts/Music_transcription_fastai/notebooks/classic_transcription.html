<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Most interesting blog on Earth! – classic_transcription</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Most interesting blog on Earth!</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
 <span class="menu-text">Aetius Lee</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ShiYang1101"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://linkedin.com/in/shi-yang-lee"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">



<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> librosa</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> LSTM, ConvLSTM1D, Input, MaxPool1D</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers.convolutional <span class="im">import</span> Conv2D, MaxPooling2D, SeparableConv2D</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers.core <span class="im">import</span> Dense, Dropout, Flatten</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Model, Sequential</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> librosa <span class="im">import</span> display</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> classic_generator <span class="im">import</span> classic_generator</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> spectrogram_class <span class="im">import</span> spectrogram</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>ModuleNotFoundError: No module named 'classic_generator'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pwd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>/Users/ylee/Downloads</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> save_history(history, path):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(path, <span class="st">'wb+'</span>) <span class="im">as</span> f:</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        pickle.dump(history, f)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_history(path):</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(path, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> pickle.load(f)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="music-transcription---musicnet-lstm" class="level1">
<h1>Music transcription - MusicNet LSTM</h1>
<p>This is a successive notebook from RNN models for OrchideaSOL dataset. In that notebook, we have demonstrate that the RNN model, in particularly LSTM, is able to capture the features of instrument and pitch in a raw audio file.</p>
<p>The purpose of this notebook is to apply the same principle on the more complicated MusicNet dataset. On our previous notebook, we have had mild success of predicting more than 50% in both insturment and notes, for short single instrumental audio files.</p>
<p>Although it is the same principle, this time we are going to need to convert the whole sequence of audio file into the transcription in to the same music file length. To be more clear:</p>
<blockquote class="blockquote">
<p>For all timesteps in the spectrogram, we are going to produce the classification of instruments and note.</p>
</blockquote>
<p>The end goal of this project is to convert the corresponding output into a MIDI file.</p>
<p>The model architecture will be to be fine tuned since we are facing the challenges below:</p>
<ul>
<li>We are making classifying prediction for every timestep,<br>
</li>
<li>Excluding the expected dimension of time and notes as output, we also need the same classification for every instruments, which is 11 of them.</li>
<li>The audio files are not neccessarily made of single instrument, which means that our RNN model will need to find the relation of the sound signature for each instruments, in the sea of spectrogram’s magnitude.</li>
<li>The audio files has different length, range from 3 minutes to 20 minutes. Padding will be required, however, zeros padding will cause problem of exploding/vanishing gradient in RNN model.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Testing if GPU is enabled, if it's not, I am not running this notebook!</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>tf.config.list_physical_devices(<span class="st">'GPU'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>tf.test.is_built_with_cuda()</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>tf.test.is_gpu_available(cuda_only<span class="op">=</span><span class="va">False</span>, min_cuda_compute_capability<span class="op">=</span><span class="va">None</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>WARNING:tensorflow:From /var/folders/n9/gg0_718d4db65yyqhxlk09vh0000gp/T/ipykernel_38191/1822807733.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.config.list_physical_devices('GPU')` instead.
Metal device set to: Apple M1

systemMemory: 8.00 GB
maxCacheSize: 2.67 GB
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-09-16 16:43:02.967559: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2022-09-16 16:43:02.968025: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -&gt; physical PluggableDevice (device: 0, name: METAL, pci bus id: &lt;undefined&gt;)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.python.client <span class="im">import</span> device_lib</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(device_lib.list_local_devices())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 3715140090454835554
xla_global_id: -1
, name: "/device:GPU:0"
device_type: "GPU"
locality {
  bus_id: 1
}
incarnation: 11023430109333998903
physical_device_desc: "device: 0, name: METAL, pci bus id: &lt;undefined&gt;"
xla_global_id: -1
]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-09-16 16:43:03.107869: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2022-09-16 16:43:03.107888: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -&gt; physical PluggableDevice (device: 0, name: METAL, pci bus id: &lt;undefined&gt;)</code></pre>
</div>
</div>
<p>Throughout this notebook, we will be using integer code number for instrument and notes classification. The instrument and note lists below are generated by concatenating the training labels, which are seperated csv files.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>instrument_list <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">41</span>, <span class="dv">42</span>, <span class="dv">43</span>, <span class="dv">44</span>, <span class="dv">61</span>, <span class="dv">69</span>, <span class="dv">71</span>, <span class="dv">72</span>, <span class="dv">74</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>note_list <span class="op">=</span> [<span class="dv">21</span>, <span class="dv">23</span>, <span class="dv">24</span>, <span class="dv">25</span>, <span class="dv">26</span>, <span class="dv">27</span>, <span class="dv">28</span>, <span class="dv">29</span>, <span class="dv">30</span>, <span class="dv">31</span>, <span class="dv">32</span>, <span class="dv">33</span>, <span class="dv">34</span>, <span class="dv">35</span>, <span class="dv">36</span>, <span class="dv">37</span>, <span class="dv">38</span>, <span class="dv">39</span>, <span class="dv">40</span>, <span class="dv">41</span>, <span class="dv">42</span>, <span class="dv">43</span>, <span class="dv">44</span>, <span class="dv">45</span>, <span class="dv">46</span>, <span class="dv">47</span>, <span class="dv">48</span>, <span class="dv">49</span>, <span class="dv">50</span>, <span class="dv">51</span>, <span class="dv">52</span>, <span class="dv">53</span>, <span class="dv">54</span>, <span class="dv">55</span>, <span class="dv">56</span>, <span class="dv">57</span>, <span class="dv">58</span>, <span class="dv">59</span>, <span class="dv">60</span>, <span class="dv">61</span>, <span class="dv">62</span>,</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>             <span class="dv">63</span>, <span class="dv">64</span>, <span class="dv">65</span>, <span class="dv">66</span>, <span class="dv">67</span>, <span class="dv">68</span>, <span class="dv">69</span>, <span class="dv">70</span>, <span class="dv">71</span>, <span class="dv">72</span>, <span class="dv">73</span>, <span class="dv">74</span>, <span class="dv">75</span>, <span class="dv">76</span>, <span class="dv">77</span>, <span class="dv">78</span>, <span class="dv">79</span>, <span class="dv">80</span>, <span class="dv">81</span>, <span class="dv">82</span>, <span class="dv">83</span>, <span class="dv">84</span>, <span class="dv">85</span>, <span class="dv">86</span>, <span class="dv">87</span>, <span class="dv">88</span>, <span class="dv">89</span>, <span class="dv">90</span>, <span class="dv">91</span>, <span class="dv">92</span>, <span class="dv">93</span>, <span class="dv">94</span>, <span class="dv">95</span>, <span class="dv">96</span>, <span class="dv">97</span>, <span class="dv">98</span>, <span class="dv">99</span>, <span class="dv">100</span>, <span class="dv">101</span>, <span class="dv">102</span>, <span class="dv">103</span>, <span class="dv">104</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="rnn-lstm" class="level1">
<h1>RNN-LSTM</h1>
<p>To begin our construction of RNN model, we introduce the architect idea for our model.</p>
<p>Since our model has to output the MIDI file equivalence for each instruments, we will be forking our output into 11 Dense layers, with each layer reprenting one instruments.</p>
<p>Each output will have a dimension of : <span class="math display">\[
\text{\# of instruments} \times (\text{\# of timesteps} \times \text{\# of notes})
\]</span></p>
<p>The architect idea for the model is as follow: 1. Passing input spectrogrom into convolutional layers, in order to extract features 1. Passing features in to multiple layers of Dense layers, to embed the features 1. Passing embedded features into LSTM model, to predict labels for each timestep depending on the sequnce of embedded features.</p>
<section id="update" class="level3">
<h3 class="anchored" data-anchor-id="update">UPDATE:</h3>
<p>After countless time wasted on differnet architect and changing parameter, we have decided to change the input shape, instead of feeding the batch of spectrogram which are padded with the longest time dimension across the batch, we will be taken random snipshot of fixed time length across all batch. This workaround is to prevent:<br>
* Long padding of zeros for shorter audio files, to prevent vanishing gradient * Long training time and * Reduce GPU memory usage (VsCode tends to close unexpectedly and doesn’t release allocated GPU space before closing, making a full system restart required.)</p>
<p>We have decided to take 200 timeslices for the model input, with our default hop length (number of timestep to skip when computing fast-fourier transform for spectrogram), and using the sample rate of audio, which is 44100HZ, we can calculate that:</p>
<p><span class="math display">\[
\text{Length in second of inputs} = \frac{300 \times 200}{44100} \\
\approx 16 \, \text{seconds}
\]</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> instrument_layer_simple(<span class="bu">input</span>, out_name):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Support function from building multiple output models. Returns an output layer</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">    of TimeDistributed Dense layer, corresponds to the number of notes in labels</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Input:</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">    input: Preceeding input layer to be fed into.</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">    out_name: str, name of output layer names to be assigned</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> layers.TimeDistributed(Dense(<span class="bu">len</span>(note_list), activation<span class="op">=</span><span class="st">'sigmoid'</span>),</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>                                 name<span class="op">=</span>out_name)(<span class="bu">input</span>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>instrument_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>[1, 7, 41, 42, 43, 44, 61, 69, 71, 72, 74]</code></pre>
</div>
</div>
<p>Now we can start to build our (hopefully will be working this time) model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We have choose to work with 128 frequency bins,</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># and the None input shape indicates the dynamic length of time dimension</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>inp <span class="op">=</span> Input((<span class="va">None</span>, <span class="dv">128</span>, <span class="dv">1</span>), batch_size<span class="op">=</span>BATCH_SIZE)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>normalizer <span class="op">=</span> layers.BatchNormalization()(inp)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Extracting features from first convolutional layers.</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Padding set to same to maintain same time dimension</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>conv_1 <span class="op">=</span> Conv2D(<span class="dv">10</span>, (<span class="dv">50</span>, <span class="dv">40</span>), padding <span class="op">=</span> <span class="st">'same'</span>)(normalizer)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>normalizer_2 <span class="op">=</span> layers.BatchNormalization()(conv_1)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co"># pool_1 = layers.TimeDistributed(MaxPool1D(2))(normalizer_2)</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="co"># flatten_1 = flatten = layers.TimeDistributed(layers.Flatten())(pool_1)</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="co"># conv_2 = layers.Conv2D(5, (1000, 30), padding = 'same')(pool_1)</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="co"># pool_2 = layers.TimeDistributed(layers.MaxPool1D(2))(conv_2)</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Flatten each filter layer for each timesteps</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>flatten <span class="op">=</span> layers.TimeDistributed(Flatten())(normalizer_2)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Feed in the flattened layers to multiple layers of Dense layer,</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Performing embedding</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>Dense_1 <span class="op">=</span> layers.TimeDistributed(Dense(<span class="dv">300</span>, activation <span class="op">=</span> <span class="st">'relu'</span>))(flatten)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>normalizer_3 <span class="op">=</span> layers.BatchNormalization()(Dense_1)</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>drop_1 <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(normalizer_3)</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>Dense_2 <span class="op">=</span> layers.TimeDistributed(Dense(<span class="dv">150</span>, activation <span class="op">=</span> <span class="st">'relu'</span>))(drop_1)</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>normalizer_4 <span class="op">=</span> layers.BatchNormalization()(Dense_2)</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>drop_2 <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(normalizer_4)</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>Dense_3 <span class="op">=</span> layers.TimeDistributed(Dense(<span class="dv">50</span>, activation <span class="op">=</span> <span class="st">'relu'</span>))(drop_2)</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>normalizer_5 <span class="op">=</span> layers.BatchNormalization()(Dense_3)</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>drop_3 <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(normalizer_5)</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>Dense_3 <span class="op">=</span> layers.TimeDistributed(Dense(<span class="dv">200</span>, activation <span class="op">=</span> <span class="st">'relu'</span>))(drop_2)</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>normalizer_5 <span class="op">=</span> layers.BatchNormalization()(Dense_3)</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>drop_3 <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(normalizer_5)</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Lastly, put the decoded features in to LSTM layer</span></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>last_lstm <span class="op">=</span> LSTM(<span class="dv">500</span>, return_sequences<span class="op">=</span><span class="va">True</span>, dropout <span class="op">=</span> <span class="fl">0.3</span>)(drop_3)</span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Outputing to final Dense layer with sigmoid activation,</span></span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a><span class="co"># To predict the note labels for each timesteps</span></span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>simple_lstm_model <span class="op">=</span> Model(inp, [instrument_layer_simple(last_lstm,</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>                                <span class="ss">f"instrument_</span><span class="sc">{</span>ins<span class="sc">}</span><span class="ss">"</span>) <span class="cf">for</span> ins <span class="kw">in</span> instrument_list])</span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-09-16 16:43:04.148904: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2022-09-16 16:43:04.148928: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -&gt; physical PluggableDevice (device: 0, name: METAL, pci bus id: &lt;undefined&gt;)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>tf.keras.utils.plot_model(simple_lstm_model, show_shapes<span class="op">=</span><span class="va">True</span>, show_dtype<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<p><img src="classic_transcription_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>classic_train_generator <span class="op">=</span>  classic_generator(mode<span class="op">=</span><span class="st">'train'</span>, batch_size<span class="op">=</span>BATCH_SIZE)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># (tf.dtypes.float32, tf.dtypes.bool))</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>classic_eval_generator <span class="op">=</span> classic_generator(mode<span class="op">=</span><span class="st">'test'</span>, batch_size<span class="op">=</span>BATCH_SIZE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Getting the path to the latest trained model</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>newest_ckpt <span class="op">=</span> <span class="op">!</span>ls <span class="op">-</span>dt $PWD<span class="op">/</span>..<span class="op">/</span>models<span class="op">/</span>classic_truc_conv_to_lstm<span class="op">/*</span> <span class="op">|</span> head <span class="op">-</span><span class="dv">1</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>newest_ckpt <span class="op">=</span> newest_ckpt[<span class="dv">0</span>]</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>newest_ckpt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>'/Users/ylee/Documents/Music_transcription_fastai/notebooks/../models/classic_truc_conv_to_lstm/20220916_135022_02_classic_truc_conv_to_lstm'</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the following code to load the newest model</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>simple_lstm_model <span class="op">=</span> tf.keras.models.load_model(newest_ckpt, <span class="bu">compile</span><span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Since our prediction will be a really sparse metrics, with a few 1s, we will need to define our custom loss function such that the false negatives are hugely reduced. We will be using the weighted_cross_entropy_with_logits in tensorflow, and setting positive weight which is larger than 1.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> weighted_cross_entropy_with_logits(labels, logits):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> tf.nn.weighted_cross_entropy_with_logits(</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>        labels, logits, pos_weight <span class="op">=</span> <span class="dv">150</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> my_loss():</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> weighted_cross_entropy_with_logits</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co"># As mentioned before, since our prediction is a sparse multilabel problem, </span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co"># the accuracy might not makes muc of sense, in addition, we will be adding</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="co"># AUC for each instrument to gauge how well the model is performing</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>simple_lstm_model.<span class="bu">compile</span>(optimizer<span class="op">=</span>tf.keras.optimizers.RMSprop(learning_rate <span class="op">=</span> <span class="fl">0.0005</span>),</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>                          loss<span class="op">=</span>{<span class="ss">f"instrument_</span><span class="sc">{</span>ins<span class="sc">}</span><span class="ss">"</span>: my_loss()</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>                                <span class="cf">for</span> ins <span class="kw">in</span> instrument_list},</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>                          metrics<span class="op">=</span>[<span class="st">'accuracy'</span>, tf.keras.metrics.AUC()])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>NameError: name 'simple_lstm_model' is not defined</code></pre>
</div>
</div>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define checkpoint to save model for every epoch</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>ckpt_callback <span class="op">=</span> tf.keras.callbacks.ModelCheckpoint(</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f"../models/classic_truc_conv_to_lstm/</span><span class="sc">{</span>datetime<span class="sc">.</span>now()<span class="sc">.</span>strftime(<span class="st">'%Y%m</span><span class="sc">%d</span><span class="st">_%H%M%S'</span>)<span class="sc">}</span><span class="ss">_</span><span class="ch">{{</span><span class="ss">epoch:02d</span><span class="ch">}}</span><span class="ss">_classic_truc_conv_to_lstm"</span>,</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_accuracy'</span>,</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    save_freq<span class="op">=</span><span class="st">'epoch'</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define checkpoint to save model if validation loss is decreasing</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>early_callback <span class="op">=</span> tf.keras.callbacks.EarlyStopping(</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>simple_lstm_history <span class="op">=</span> simple_lstm_model.fit(classic_train_generator, </span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>                                                epochs<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>                                                validation_data<span class="op">=</span>classic_eval_generator,</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>                                                validation_freq<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>                                                <span class="co"># use_multiprocessing= True,</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>                                                <span class="co"># workers= 3,</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>                                                verbose<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>                                                callbacks<span class="op">=</span>[ckpt_callback])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>NameError: name 'tf' is not defined</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># simple_lstm_model.save('../models/classic_full_convlstm/')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Since we have multiple output with 2 dimensional output, it is easier to use visualization to gauge how well the model is performing.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> musicnet_eval(model, generator, ins):</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Supporting function to  plot the predicted label and true labels</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co">    of for specified instrument.</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Input:</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co">    model: model to be used</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co">    generator: testing Sequence generator to be used</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co">    ins: int, instrument number, ranged from 0 to 10</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>    _feature, _label <span class="op">=</span> generator.<span class="fu">__getitem__</span>(<span class="dv">0</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>    _prediction <span class="op">=</span> model.predict(_feature)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span> (<span class="dv">18</span>, <span class="dv">6</span>))</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>    ax_1 <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>)</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>    ax_1.set_title(<span class="st">'Prediction'</span>)</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(_prediction[ins][<span class="dv">0</span>], ax <span class="op">=</span> ax_1)</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>    ax_2 <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>)</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(_label[<span class="ss">f"instrument_</span><span class="sc">{</span>instrument_list[ins]<span class="sc">}</span><span class="ss">"</span>][<span class="dv">0</span>], ax <span class="op">=</span> ax_2)</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>    ax_2.set_title(<span class="st">'True label'</span>)</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Frequency bins'</span>)</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Timesteps'</span>)</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>test_generator <span class="op">=</span> classic_generator(mode<span class="op">=</span><span class="st">'test'</span>, batch_size<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>musicnet_eval(simple_lstm_model, test_generator, <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 2s 2s/step</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="classic_transcription_files/figure-html/cell-23-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>test_set <span class="op">=</span> test_generator.<span class="fu">__getitem__</span>(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>test_set[<span class="dv">0</span>].shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>(1, 200, 128, 1)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>predict_test <span class="op">=</span> simple_lstm_model.predict(test_set[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 25ms/step</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>instrument_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>[1, 7, 41, 42, 43, 44, 61, 69, 71, 72, 74]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>sns.heatmap(test_set[<span class="dv">1</span>][<span class="st">'instrument_41'</span>][<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>&lt;AxesSubplot:&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="classic_transcription_files/figure-html/cell-28-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>instrument_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>[1, 7, 41, 42, 43, 44, 61, 69, 71, 72, 74]</code></pre>
</div>
</div>
<p>The problem with this model is that the model is predicting contant value along timesteps. The model focused and retained the sequential relation across timesteps too much. And eventually learned to predict zeros for all scenarios. Look at figure below for a better visualization.</p>
</section>
</section>
<section id="lstm" class="level1">
<h1>2 lstm</h1>
<p>Our first model produced unsatisfactory results, which implies we might have to start from a simpler model, we will be starting again at a model with 2 LSTM layers.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>inp <span class="op">=</span> Input((<span class="va">None</span>, <span class="dv">128</span>), batch_size<span class="op">=</span>BATCH_SIZE)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2 LSTM layers</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> LSTM(<span class="dv">500</span>, return_sequences<span class="op">=</span><span class="va">True</span>, dropout <span class="op">=</span> <span class="fl">0.3</span>, stateful <span class="op">=</span> <span class="va">True</span>)(inp)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> LSTM(<span class="dv">500</span>, return_sequences<span class="op">=</span><span class="va">True</span>, dropout <span class="op">=</span> <span class="fl">0.3</span>, stateful <span class="op">=</span> <span class="va">True</span>)(x)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>lstm_2 <span class="op">=</span> Model(inp, [instrument_layer_simple(x,</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>                                <span class="ss">f"instrument_</span><span class="sc">{</span>ins<span class="sc">}</span><span class="ss">"</span>) <span class="cf">for</span> ins <span class="kw">in</span> instrument_list])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>tf.keras.utils.plot_model(lstm_2, show_shapes<span class="op">=</span><span class="va">True</span>, show_dtype<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<p><img src="classic_transcription_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>lstm2_train_generator <span class="op">=</span>  classic_generator(mode<span class="op">=</span><span class="st">'train'</span>, batch_size<span class="op">=</span>BATCH_SIZE, expand_dim <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># (tf.dtypes.float32, tf.dtypes.bool))</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>lstm2_eval_generator <span class="op">=</span> classic_generator(mode<span class="op">=</span><span class="st">'test'</span>, batch_size<span class="op">=</span>BATCH_SIZE, expand_dim <span class="op">=</span> <span class="va">False</span>, </span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>                                            preprocess <span class="op">=</span> <span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> weighted_cross_entropy_with_logits(labels, logits):</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> tf.nn.weighted_cross_entropy_with_logits(</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>        labels, logits, pos_weight <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> my_loss():</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> weighted_cross_entropy_with_logits</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>lstm_2.<span class="bu">compile</span>(optimizer<span class="op">=</span>tf.keras.optimizers.RMSprop(learning_rate <span class="op">=</span> <span class="fl">0.001</span>),</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>                          loss<span class="op">=</span>{<span class="ss">f"instrument_</span><span class="sc">{</span>ins<span class="sc">}</span><span class="ss">"</span>: my_loss()</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>                                <span class="cf">for</span> ins <span class="kw">in</span> instrument_list},</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>                          metrics<span class="op">=</span>[<span class="st">'accuracy'</span>, tf.keras.metrics.AUC()])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>ckpt_callback <span class="op">=</span> tf.keras.callbacks.ModelCheckpoint(</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f"../models/classic_lstm2/</span><span class="sc">{</span>datetime<span class="sc">.</span>now()<span class="sc">.</span>strftime(<span class="st">'%Y%m</span><span class="sc">%d</span><span class="st">_%H%M%S'</span>)<span class="sc">}</span><span class="ss">_</span><span class="ch">{{</span><span class="ss">epoch:02d</span><span class="ch">}}</span><span class="ss">_classic_lstm2"</span>,</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_accuracy'</span>,</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>    save_freq<span class="op">=</span><span class="st">'epoch'</span>)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>early_callback <span class="op">=</span> tf.keras.callbacks.EarlyStopping(</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>lstm2_history <span class="op">=</span> lstm_2.fit(lstm2_train_generator, </span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>                            epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>                            validation_data<span class="op">=</span>lstm2_eval_generator,</span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>                            validation_freq<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>                            use_multiprocessing<span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>                            workers<span class="op">=</span> <span class="dv">3</span>,</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>                            verbose<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>                            callbacks<span class="op">=</span>[ckpt_callback])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>NameError: name 'lstm_2' is not defined</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>musicnet_eval(lstm_2, test_generator, <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 37ms/step</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="classic_transcription_files/figure-html/cell-35-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>We still observe the same pattern, that constant values are passed along the timesteps.</p>
<p>The x-axis above represents the 81 notes, and y-axis represetns the timesteps.</p>
<p>The figure on the left represents the prediction of our model, whereas the right figure represents the true labels.</p>
</section>
<section id="conv-to-lstm" class="level1">
<h1>Conv to lstm</h1>
<p>Attempts last architecture of padding filters of convolutional layers to LSTM layers. This is the most basic model that extract features by convolutional layers, and passing the feature through the sequnce to make a prediction.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We have choose to work with 128 frequency bins,</span></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># and the None input shape indicates the dynamic length of time dimension</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>inp <span class="op">=</span> Input((<span class="va">None</span>, <span class="dv">128</span>, <span class="dv">1</span>), batch_size<span class="op">=</span>BATCH_SIZE)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>normalizer <span class="op">=</span> layers.BatchNormalization()(inp)</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Extracting features from first convolutional layers.</span></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Padding set to same to maintain same time dimension</span></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>conv_1 <span class="op">=</span> Conv2D(<span class="dv">30</span>, (<span class="dv">50</span>, <span class="dv">40</span>), padding <span class="op">=</span> <span class="st">'same'</span>)(normalizer)</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>normalizer_2 <span class="op">=</span> layers.BatchNormalization()(conv_1)</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a><span class="co"># pool_1 = layers.TimeDistributed(MaxPool1D(2))(normalizer_2)</span></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a><span class="co"># flatten_1 = flatten = layers.TimeDistributed(layers.Flatten())(pool_1)</span></span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a><span class="co"># conv_2 = layers.Conv2D(5, (1000, 30), padding = 'same')(pool_1)</span></span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a><span class="co"># pool_2 = layers.TimeDistributed(layers.MaxPool1D(2))(conv_2)</span></span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Flatten each filter layer for each timesteps</span></span>
<span id="cb55-20"><a href="#cb55-20" aria-hidden="true" tabindex="-1"></a>flatten <span class="op">=</span> layers.TimeDistributed(Flatten())(normalizer_2)</span>
<span id="cb55-21"><a href="#cb55-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-22"><a href="#cb55-22" aria-hidden="true" tabindex="-1"></a>drop_1 <span class="op">=</span> layers.Dropout(<span class="fl">0.3</span>)(flatten)</span>
<span id="cb55-23"><a href="#cb55-23" aria-hidden="true" tabindex="-1"></a><span class="co"># # Feed in the flattened layers to multiple layers of Dense layer,</span></span>
<span id="cb55-24"><a href="#cb55-24" aria-hidden="true" tabindex="-1"></a><span class="co"># # Performing embedding</span></span>
<span id="cb55-25"><a href="#cb55-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Dense_1 = layers.TimeDistributed(Dense(300, activation = 'relu'))(flatten)</span></span>
<span id="cb55-26"><a href="#cb55-26" aria-hidden="true" tabindex="-1"></a><span class="co"># normalizer_3 = layers.BatchNormalization()(Dense_1)</span></span>
<span id="cb55-27"><a href="#cb55-27" aria-hidden="true" tabindex="-1"></a><span class="co"># drop_1 = layers.Dropout(0.2)(normalizer_3)</span></span>
<span id="cb55-28"><a href="#cb55-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-29"><a href="#cb55-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Dense_2 = layers.TimeDistributed(Dense(150, activation = 'relu'))(drop_1)</span></span>
<span id="cb55-30"><a href="#cb55-30" aria-hidden="true" tabindex="-1"></a><span class="co"># normalizer_4 = layers.BatchNormalization()(Dense_2)</span></span>
<span id="cb55-31"><a href="#cb55-31" aria-hidden="true" tabindex="-1"></a><span class="co"># drop_2 = layers.Dropout(0.2)(normalizer_4)</span></span>
<span id="cb55-32"><a href="#cb55-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-33"><a href="#cb55-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Dense_3 = layers.TimeDistributed(Dense(50, activation = 'relu'))(drop_2)</span></span>
<span id="cb55-34"><a href="#cb55-34" aria-hidden="true" tabindex="-1"></a><span class="co"># normalizer_5 = layers.BatchNormalization()(Dense_3)</span></span>
<span id="cb55-35"><a href="#cb55-35" aria-hidden="true" tabindex="-1"></a><span class="co"># drop_3 = layers.Dropout(0.2)(normalizer_5)</span></span>
<span id="cb55-36"><a href="#cb55-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-37"><a href="#cb55-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Dense_3 = layers.TimeDistributed(Dense(200, activation = 'relu'))(drop_2)</span></span>
<span id="cb55-38"><a href="#cb55-38" aria-hidden="true" tabindex="-1"></a><span class="co"># normalizer_5 = layers.BatchNormalization()(Dense_3)</span></span>
<span id="cb55-39"><a href="#cb55-39" aria-hidden="true" tabindex="-1"></a><span class="co"># drop_3 = layers.Dropout(0.2)(normalizer_5)</span></span>
<span id="cb55-40"><a href="#cb55-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-41"><a href="#cb55-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Lastly, put the decoded features in to LSTM layer</span></span>
<span id="cb55-42"><a href="#cb55-42" aria-hidden="true" tabindex="-1"></a>last_lstm <span class="op">=</span> LSTM(<span class="dv">500</span>, return_sequences<span class="op">=</span><span class="va">True</span>, dropout <span class="op">=</span> <span class="fl">0.3</span>)(drop_1)</span>
<span id="cb55-43"><a href="#cb55-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-44"><a href="#cb55-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Outputing to final Dense layer with sigmoid activation,</span></span>
<span id="cb55-45"><a href="#cb55-45" aria-hidden="true" tabindex="-1"></a><span class="co"># To predict the note labels for each timesteps</span></span>
<span id="cb55-46"><a href="#cb55-46" aria-hidden="true" tabindex="-1"></a>conv_to_lstm_model <span class="op">=</span> Model(inp, [instrument_layer_simple(last_lstm,</span>
<span id="cb55-47"><a href="#cb55-47" aria-hidden="true" tabindex="-1"></a>                                <span class="ss">f"instrument_</span><span class="sc">{</span>ins<span class="sc">}</span><span class="ss">"</span>) <span class="cf">for</span> ins <span class="kw">in</span> instrument_list])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>tf.keras.utils.plot_model(conv_to_lstm_model, show_shapes<span class="op">=</span><span class="va">True</span>, show_dtype<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<p><img src="classic_transcription_files/figure-html/cell-37-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>classic_train_generator <span class="op">=</span>  classic_generator(mode<span class="op">=</span><span class="st">'train'</span>, batch_size<span class="op">=</span>BATCH_SIZE)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># (tf.dtypes.float32, tf.dtypes.bool))</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>classic_eval_generator <span class="op">=</span> classic_generator(mode<span class="op">=</span><span class="st">'test'</span>, batch_size<span class="op">=</span>BATCH_SIZE, preprocess <span class="op">=</span> <span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> weighted_cross_entropy_with_logits(labels, logits):</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> tf.nn.weighted_cross_entropy_with_logits(</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>        labels, logits, pos_weight <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> my_loss():</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> weighted_cross_entropy_with_logits</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a><span class="co"># As mentioned before, since our prediction is a sparse multilabel problem, </span></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a><span class="co"># the accuracy might not makes muc of sense, in addition, we will be adding</span></span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a><span class="co"># AUC for each instrument to gauge how well the model is performing</span></span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>conv_to_lstm_model.<span class="bu">compile</span>(optimizer<span class="op">=</span>tf.keras.optimizers.Adam(learning_rate <span class="op">=</span> <span class="fl">0.0001</span>),</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>                          loss<span class="op">=</span>{<span class="ss">f"instrument_</span><span class="sc">{</span>ins<span class="sc">}</span><span class="ss">"</span>: my_loss() </span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>                                <span class="cf">for</span> ins <span class="kw">in</span> instrument_list},</span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>                          metrics<span class="op">=</span>[<span class="st">'accuracy'</span>, tf.keras.metrics.AUC()])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>ckpt_callback <span class="op">=</span> tf.keras.callbacks.ModelCheckpoint(</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f"../models/classic_direct_conv_to_lstm/</span><span class="sc">{</span>datetime<span class="sc">.</span>now()<span class="sc">.</span>strftime(<span class="st">'%Y%m</span><span class="sc">%d</span><span class="st">_%H%M%S'</span>)<span class="sc">}</span><span class="ss">_</span><span class="ch">{{</span><span class="ss">epoch:02d</span><span class="ch">}}</span><span class="ss">_classic_direct_conv_to_lstm"</span>,</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_accuracy'</span>,</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>    save_freq<span class="op">=</span><span class="st">'epoch'</span>)</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>early_callback <span class="op">=</span> tf.keras.callbacks.EarlyStopping(</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a>conv_to_lstm_history <span class="op">=</span> conv_to_lstm_model.fit(classic_train_generator, </span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a>                                                epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a>                                                validation_data<span class="op">=</span>classic_eval_generator,</span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a>                                                validation_freq<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a>                                                <span class="co"># use_multiprocessing= True,</span></span>
<span id="cb59-17"><a href="#cb59-17" aria-hidden="true" tabindex="-1"></a>                                                <span class="co"># workers= 3,</span></span>
<span id="cb59-18"><a href="#cb59-18" aria-hidden="true" tabindex="-1"></a>                                                verbose<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb59-19"><a href="#cb59-19" aria-hidden="true" tabindex="-1"></a>                                                <span class="co"># class_weight= {0: 0.11, 1: 0.89}, </span></span>
<span id="cb59-20"><a href="#cb59-20" aria-hidden="true" tabindex="-1"></a>                                                callbacks<span class="op">=</span>[ckpt_callback])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-08-07 18:44:58.981777: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100
2022-08-07 18:44:59.811714: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2022-08-07 18:44:59.813228: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2022-08-07 18:44:59.813276: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version
2022-08-07 18:44:59.814714: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2022-08-07 18:44:59.814829: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>40/40 [==============================] - ETA: 0s - loss: 9.4632 - instrument_1_loss: 0.9001 - instrument_7_loss: 0.8716 - instrument_41_loss: 0.8497 - instrument_42_loss: 0.8685 - instrument_43_loss: 0.8520 - instrument_44_loss: 0.8687 - instrument_61_loss: 0.8508 - instrument_69_loss: 0.8303 - instrument_71_loss: 0.8733 - instrument_72_loss: 0.8566 - instrument_74_loss: 0.8417 - instrument_1_accuracy: 0.0041 - instrument_1_auc_1: 0.4734 - instrument_7_accuracy: 0.0077 - instrument_7_auc_1: 0.3513 - instrument_41_accuracy: 0.0077 - instrument_41_auc_1: 0.5359 - instrument_42_accuracy: 0.0058 - instrument_42_auc_1: 0.5681 - instrument_43_accuracy: 0.0010 - instrument_43_auc_1: 0.5255 - instrument_44_accuracy: 0.0014 - instrument_44_auc_1: 0.5647 - instrument_61_accuracy: 0.0016 - instrument_61_auc_1: 0.4531 - instrument_69_accuracy: 0.0015 - instrument_69_auc_1: 0.6652 - instrument_71_accuracy: 0.0340 - instrument_71_auc_1: 0.6068 - instrument_72_accuracy: 6.7188e-04 - instrument_72_auc_1: 0.5844 - instrument_74_accuracy: 0.0421 - instrument_74_auc_1: 0.5877 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.
2022-08-07 19:00:44.902483: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2022-08-07 19:00:44.963806: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2022-08-07 19:00:44.996746: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_01_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_01_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>40/40 [==============================] - 977s 24s/step - loss: 9.4632 - instrument_1_loss: 0.9001 - instrument_7_loss: 0.8716 - instrument_41_loss: 0.8497 - instrument_42_loss: 0.8685 - instrument_43_loss: 0.8520 - instrument_44_loss: 0.8687 - instrument_61_loss: 0.8508 - instrument_69_loss: 0.8303 - instrument_71_loss: 0.8733 - instrument_72_loss: 0.8566 - instrument_74_loss: 0.8417 - instrument_1_accuracy: 0.0041 - instrument_1_auc_1: 0.4734 - instrument_7_accuracy: 0.0077 - instrument_7_auc_1: 0.3513 - instrument_41_accuracy: 0.0077 - instrument_41_auc_1: 0.5359 - instrument_42_accuracy: 0.0058 - instrument_42_auc_1: 0.5681 - instrument_43_accuracy: 0.0010 - instrument_43_auc_1: 0.5255 - instrument_44_accuracy: 0.0014 - instrument_44_auc_1: 0.5647 - instrument_61_accuracy: 0.0016 - instrument_61_auc_1: 0.4531 - instrument_69_accuracy: 0.0015 - instrument_69_auc_1: 0.6652 - instrument_71_accuracy: 0.0340 - instrument_71_auc_1: 0.6068 - instrument_72_accuracy: 6.7188e-04 - instrument_72_auc_1: 0.5844 - instrument_74_accuracy: 0.0421 - instrument_74_auc_1: 0.5877 - val_loss: 8.4378 - val_instrument_1_loss: 0.8021 - val_instrument_7_loss: 0.7764 - val_instrument_41_loss: 0.7603 - val_instrument_42_loss: 0.7667 - val_instrument_43_loss: 0.7576 - val_instrument_44_loss: 0.7714 - val_instrument_61_loss: 0.7615 - val_instrument_69_loss: 0.7426 - val_instrument_71_loss: 0.7806 - val_instrument_72_loss: 0.7687 - val_instrument_74_loss: 0.7498 - val_instrument_1_accuracy: 0.0000e+00 - val_instrument_1_auc_1: 0.4493 - val_instrument_7_accuracy: 0.0000e+00 - val_instrument_7_auc_1: 0.0000e+00 - val_instrument_41_accuracy: 0.0069 - val_instrument_41_auc_1: 0.5197 - val_instrument_42_accuracy: 0.0031 - val_instrument_42_auc_1: 0.5051 - val_instrument_43_accuracy: 0.0000e+00 - val_instrument_43_auc_1: 0.5542 - val_instrument_44_accuracy: 0.0000e+00 - val_instrument_44_auc_1: 0.0000e+00 - val_instrument_61_accuracy: 0.0019 - val_instrument_61_auc_1: 0.4583 - val_instrument_69_accuracy: 0.0000e+00 - val_instrument_69_auc_1: 0.0000e+00 - val_instrument_71_accuracy: 0.0000e+00 - val_instrument_71_auc_1: 0.5306 - val_instrument_72_accuracy: 0.0000e+00 - val_instrument_72_auc_1: 0.5087 - val_instrument_74_accuracy: 0.0000e+00 - val_instrument_74_auc_1: 0.0000e+00
Epoch 2/10
40/40 [==============================] - ETA: 0s - loss: 8.1047 - instrument_1_loss: 0.7867 - instrument_7_loss: 0.7376 - instrument_41_loss: 0.7359 - instrument_42_loss: 0.7357 - instrument_43_loss: 0.7339 - instrument_44_loss: 0.7341 - instrument_61_loss: 0.7287 - instrument_69_loss: 0.7197 - instrument_71_loss: 0.7377 - instrument_72_loss: 0.7307 - instrument_74_loss: 0.7239 - instrument_1_accuracy: 0.0014 - instrument_1_auc_1: 0.4879 - instrument_7_accuracy: 0.0012 - instrument_7_auc_1: 0.4978 - instrument_41_accuracy: 0.0033 - instrument_41_auc_1: 0.5315 - instrument_42_accuracy: 0.0027 - instrument_42_auc_1: 0.5510 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5280 - instrument_44_accuracy: 0.0014 - instrument_44_auc_1: 0.4818 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.3864 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.6101 - instrument_71_accuracy: 0.0000e+00 - instrument_71_auc_1: 0.5646 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.5410 - instrument_74_accuracy: 0.0000e+00 - instrument_74_auc_1: 0.5612     </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.
2022-08-07 19:17:20.517681: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2022-08-07 19:17:20.554600: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_02_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_02_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>40/40 [==============================] - 995s 25s/step - loss: 8.1047 - instrument_1_loss: 0.7867 - instrument_7_loss: 0.7376 - instrument_41_loss: 0.7359 - instrument_42_loss: 0.7357 - instrument_43_loss: 0.7339 - instrument_44_loss: 0.7341 - instrument_61_loss: 0.7287 - instrument_69_loss: 0.7197 - instrument_71_loss: 0.7377 - instrument_72_loss: 0.7307 - instrument_74_loss: 0.7239 - instrument_1_accuracy: 0.0014 - instrument_1_auc_1: 0.4879 - instrument_7_accuracy: 0.0012 - instrument_7_auc_1: 0.4978 - instrument_41_accuracy: 0.0033 - instrument_41_auc_1: 0.5315 - instrument_42_accuracy: 0.0027 - instrument_42_auc_1: 0.5510 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5280 - instrument_44_accuracy: 0.0014 - instrument_44_auc_1: 0.4818 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.3864 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.6101 - instrument_71_accuracy: 0.0000e+00 - instrument_71_auc_1: 0.5646 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.5410 - instrument_74_accuracy: 0.0000e+00 - instrument_74_auc_1: 0.5612 - val_loss: 7.8978 - val_instrument_1_loss: 0.7504 - val_instrument_7_loss: 0.7148 - val_instrument_41_loss: 0.7218 - val_instrument_42_loss: 0.7141 - val_instrument_43_loss: 0.7118 - val_instrument_44_loss: 0.7135 - val_instrument_61_loss: 0.7121 - val_instrument_69_loss: 0.7065 - val_instrument_71_loss: 0.7230 - val_instrument_72_loss: 0.7210 - val_instrument_74_loss: 0.7088 - val_instrument_1_accuracy: 0.0037 - val_instrument_1_auc_1: 0.4846 - val_instrument_7_accuracy: 0.0000e+00 - val_instrument_7_auc_1: 0.0000e+00 - val_instrument_41_accuracy: 0.0100 - val_instrument_41_auc_1: 0.5245 - val_instrument_42_accuracy: 0.0031 - val_instrument_42_auc_1: 0.5151 - val_instrument_43_accuracy: 0.0000e+00 - val_instrument_43_auc_1: 0.5917 - val_instrument_44_accuracy: 0.0000e+00 - val_instrument_44_auc_1: 0.0000e+00 - val_instrument_61_accuracy: 0.0000e+00 - val_instrument_61_auc_1: 0.2997 - val_instrument_69_accuracy: 0.0000e+00 - val_instrument_69_auc_1: 0.0000e+00 - val_instrument_71_accuracy: 0.0000e+00 - val_instrument_71_auc_1: 0.5111 - val_instrument_72_accuracy: 0.0000e+00 - val_instrument_72_auc_1: 0.4152 - val_instrument_74_accuracy: 0.0000e+00 - val_instrument_74_auc_1: 0.0000e+00
Epoch 3/10
40/40 [==============================] - ETA: 0s - loss: 7.8624 - instrument_1_loss: 0.7675 - instrument_7_loss: 0.7092 - instrument_41_loss: 0.7183 - instrument_42_loss: 0.7135 - instrument_43_loss: 0.7129 - instrument_44_loss: 0.7078 - instrument_61_loss: 0.7065 - instrument_69_loss: 0.7039 - instrument_71_loss: 0.7093 - instrument_72_loss: 0.7083 - instrument_74_loss: 0.7054 - instrument_1_accuracy: 0.0159 - instrument_1_auc_1: 0.4918 - instrument_7_accuracy: 0.0010 - instrument_7_auc_1: 0.5659 - instrument_41_accuracy: 0.0036 - instrument_41_auc_1: 0.5233 - instrument_42_accuracy: 0.0012 - instrument_42_auc_1: 0.5637 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5550 - instrument_44_accuracy: 0.0020 - instrument_44_auc_1: 0.5860 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.3889 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.6318 - instrument_71_accuracy: 1.5625e-05 - instrument_71_auc_1: 0.5802 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.4675 - instrument_74_accuracy: 1.5625e-05 - instrument_74_auc_1: 0.5780 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_03_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_03_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>40/40 [==============================] - 956s 24s/step - loss: 7.8624 - instrument_1_loss: 0.7675 - instrument_7_loss: 0.7092 - instrument_41_loss: 0.7183 - instrument_42_loss: 0.7135 - instrument_43_loss: 0.7129 - instrument_44_loss: 0.7078 - instrument_61_loss: 0.7065 - instrument_69_loss: 0.7039 - instrument_71_loss: 0.7093 - instrument_72_loss: 0.7083 - instrument_74_loss: 0.7054 - instrument_1_accuracy: 0.0159 - instrument_1_auc_1: 0.4918 - instrument_7_accuracy: 0.0010 - instrument_7_auc_1: 0.5659 - instrument_41_accuracy: 0.0036 - instrument_41_auc_1: 0.5233 - instrument_42_accuracy: 0.0012 - instrument_42_auc_1: 0.5637 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5550 - instrument_44_accuracy: 0.0020 - instrument_44_auc_1: 0.5860 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.3889 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.6318 - instrument_71_accuracy: 1.5625e-05 - instrument_71_auc_1: 0.5802 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.4675 - instrument_74_accuracy: 1.5625e-05 - instrument_74_auc_1: 0.5780 - val_loss: 7.7954 - val_instrument_1_loss: 0.7227 - val_instrument_7_loss: 0.7037 - val_instrument_41_loss: 0.7197 - val_instrument_42_loss: 0.7082 - val_instrument_43_loss: 0.7105 - val_instrument_44_loss: 0.7031 - val_instrument_61_loss: 0.7064 - val_instrument_69_loss: 0.7001 - val_instrument_71_loss: 0.7094 - val_instrument_72_loss: 0.7105 - val_instrument_74_loss: 0.7012 - val_instrument_1_accuracy: 0.0031 - val_instrument_1_auc_1: 0.4640 - val_instrument_7_accuracy: 0.0000e+00 - val_instrument_7_auc_1: 0.0000e+00 - val_instrument_41_accuracy: 0.0031 - val_instrument_41_auc_1: 0.5485 - val_instrument_42_accuracy: 0.0000e+00 - val_instrument_42_auc_1: 0.6343 - val_instrument_43_accuracy: 0.0000e+00 - val_instrument_43_auc_1: 0.4931 - val_instrument_44_accuracy: 0.0000e+00 - val_instrument_44_auc_1: 0.0000e+00 - val_instrument_61_accuracy: 0.0019 - val_instrument_61_auc_1: 0.4119 - val_instrument_69_accuracy: 0.0000e+00 - val_instrument_69_auc_1: 0.0000e+00 - val_instrument_71_accuracy: 0.0000e+00 - val_instrument_71_auc_1: 0.5317 - val_instrument_72_accuracy: 0.0000e+00 - val_instrument_72_auc_1: 0.5208 - val_instrument_74_accuracy: 0.0000e+00 - val_instrument_74_auc_1: 0.0000e+00
Epoch 4/10
40/40 [==============================] - ETA: 0s - loss: 7.8032 - instrument_1_loss: 0.7629 - instrument_7_loss: 0.7022 - instrument_41_loss: 0.7141 - instrument_42_loss: 0.7073 - instrument_43_loss: 0.7084 - instrument_44_loss: 0.7014 - instrument_61_loss: 0.7015 - instrument_69_loss: 0.6996 - instrument_71_loss: 0.7028 - instrument_72_loss: 0.7026 - instrument_74_loss: 0.7005 - instrument_1_accuracy: 0.0195 - instrument_1_auc_1: 0.4969 - instrument_7_accuracy: 5.4688e-04 - instrument_7_auc_1: 0.5081 - instrument_41_accuracy: 0.0056 - instrument_41_auc_1: 0.5313 - instrument_42_accuracy: 0.0000e+00 - instrument_42_auc_1: 0.5713 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5383 - instrument_44_accuracy: 6.0938e-04 - instrument_44_auc_1: 0.5499 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.4050 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.5505 - instrument_71_accuracy: 4.6875e-05 - instrument_71_auc_1: 0.5238 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.4662 - instrument_74_accuracy: 3.1250e-05 - instrument_74_auc_1: 0.5639 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_04_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_04_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>40/40 [==============================] - 840s 21s/step - loss: 7.8032 - instrument_1_loss: 0.7629 - instrument_7_loss: 0.7022 - instrument_41_loss: 0.7141 - instrument_42_loss: 0.7073 - instrument_43_loss: 0.7084 - instrument_44_loss: 0.7014 - instrument_61_loss: 0.7015 - instrument_69_loss: 0.6996 - instrument_71_loss: 0.7028 - instrument_72_loss: 0.7026 - instrument_74_loss: 0.7005 - instrument_1_accuracy: 0.0195 - instrument_1_auc_1: 0.4969 - instrument_7_accuracy: 5.4688e-04 - instrument_7_auc_1: 0.5081 - instrument_41_accuracy: 0.0056 - instrument_41_auc_1: 0.5313 - instrument_42_accuracy: 0.0000e+00 - instrument_42_auc_1: 0.5713 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5383 - instrument_44_accuracy: 6.0938e-04 - instrument_44_auc_1: 0.5499 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.4050 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.5505 - instrument_71_accuracy: 4.6875e-05 - instrument_71_auc_1: 0.5238 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.4662 - instrument_74_accuracy: 3.1250e-05 - instrument_74_auc_1: 0.5639 - val_loss: 7.7528 - val_instrument_1_loss: 0.7379 - val_instrument_7_loss: 0.6998 - val_instrument_41_loss: 0.7096 - val_instrument_42_loss: 0.7011 - val_instrument_43_loss: 0.7045 - val_instrument_44_loss: 0.6996 - val_instrument_61_loss: 0.6999 - val_instrument_69_loss: 0.6976 - val_instrument_71_loss: 0.7014 - val_instrument_72_loss: 0.7032 - val_instrument_74_loss: 0.6983 - val_instrument_1_accuracy: 0.0113 - val_instrument_1_auc_1: 0.4940 - val_instrument_7_accuracy: 0.0000e+00 - val_instrument_7_auc_1: 0.0000e+00 - val_instrument_41_accuracy: 6.2500e-04 - val_instrument_41_auc_1: 0.5468 - val_instrument_42_accuracy: 0.0000e+00 - val_instrument_42_auc_1: 0.5828 - val_instrument_43_accuracy: 0.0000e+00 - val_instrument_43_auc_1: 0.5291 - val_instrument_44_accuracy: 0.0000e+00 - val_instrument_44_auc_1: 0.0000e+00 - val_instrument_61_accuracy: 0.0000e+00 - val_instrument_61_auc_1: 0.3873 - val_instrument_69_accuracy: 0.0000e+00 - val_instrument_69_auc_1: 0.0000e+00 - val_instrument_71_accuracy: 0.0000e+00 - val_instrument_71_auc_1: 0.6024 - val_instrument_72_accuracy: 0.0000e+00 - val_instrument_72_auc_1: 0.4427 - val_instrument_74_accuracy: 0.0000e+00 - val_instrument_74_auc_1: 0.0000e+00
Epoch 5/10
40/40 [==============================] - ETA: 0s - loss: 7.7747 - instrument_1_loss: 0.7576 - instrument_7_loss: 0.6996 - instrument_41_loss: 0.7121 - instrument_42_loss: 0.7049 - instrument_43_loss: 0.7059 - instrument_44_loss: 0.6988 - instrument_61_loss: 0.6990 - instrument_69_loss: 0.6979 - instrument_71_loss: 0.7001 - instrument_72_loss: 0.7005 - instrument_74_loss: 0.6984 - instrument_1_accuracy: 0.0180 - instrument_1_auc_1: 0.4997 - instrument_7_accuracy: 9.6875e-04 - instrument_7_auc_1: 0.4890 - instrument_41_accuracy: 0.0024 - instrument_41_auc_1: 0.5324 - instrument_42_accuracy: 0.0000e+00 - instrument_42_auc_1: 0.5521 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5446 - instrument_44_accuracy: 6.8750e-04 - instrument_44_auc_1: 0.4677 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.3171 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.6400 - instrument_71_accuracy: 0.0011 - instrument_71_auc_1: 0.5348 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.4833 - instrument_74_accuracy: 9.3750e-05 - instrument_74_auc_1: 0.5742 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_05_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_05_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>40/40 [==============================] - 809s 20s/step - loss: 7.7747 - instrument_1_loss: 0.7576 - instrument_7_loss: 0.6996 - instrument_41_loss: 0.7121 - instrument_42_loss: 0.7049 - instrument_43_loss: 0.7059 - instrument_44_loss: 0.6988 - instrument_61_loss: 0.6990 - instrument_69_loss: 0.6979 - instrument_71_loss: 0.7001 - instrument_72_loss: 0.7005 - instrument_74_loss: 0.6984 - instrument_1_accuracy: 0.0180 - instrument_1_auc_1: 0.4997 - instrument_7_accuracy: 9.6875e-04 - instrument_7_auc_1: 0.4890 - instrument_41_accuracy: 0.0024 - instrument_41_auc_1: 0.5324 - instrument_42_accuracy: 0.0000e+00 - instrument_42_auc_1: 0.5521 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5446 - instrument_44_accuracy: 6.8750e-04 - instrument_44_auc_1: 0.4677 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.3171 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.6400 - instrument_71_accuracy: 0.0011 - instrument_71_auc_1: 0.5348 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.4833 - instrument_74_accuracy: 9.3750e-05 - instrument_74_auc_1: 0.5742 - val_loss: 7.7501 - val_instrument_1_loss: 0.7305 - val_instrument_7_loss: 0.6980 - val_instrument_41_loss: 0.7178 - val_instrument_42_loss: 0.7033 - val_instrument_43_loss: 0.7052 - val_instrument_44_loss: 0.6978 - val_instrument_61_loss: 0.7014 - val_instrument_69_loss: 0.6965 - val_instrument_71_loss: 0.7022 - val_instrument_72_loss: 0.7005 - val_instrument_74_loss: 0.6969 - val_instrument_1_accuracy: 0.0094 - val_instrument_1_auc_1: 0.4634 - val_instrument_7_accuracy: 0.0000e+00 - val_instrument_7_auc_1: 0.0000e+00 - val_instrument_41_accuracy: 0.0000e+00 - val_instrument_41_auc_1: 0.5274 - val_instrument_42_accuracy: 0.0000e+00 - val_instrument_42_auc_1: 0.5837 - val_instrument_43_accuracy: 0.0000e+00 - val_instrument_43_auc_1: 0.4972 - val_instrument_44_accuracy: 0.0000e+00 - val_instrument_44_auc_1: 0.0000e+00 - val_instrument_61_accuracy: 0.0000e+00 - val_instrument_61_auc_1: 0.2460 - val_instrument_69_accuracy: 0.0000e+00 - val_instrument_69_auc_1: 0.0000e+00 - val_instrument_71_accuracy: 0.0000e+00 - val_instrument_71_auc_1: 0.5497 - val_instrument_72_accuracy: 0.0000e+00 - val_instrument_72_auc_1: 0.4621 - val_instrument_74_accuracy: 0.0000e+00 - val_instrument_74_auc_1: 0.0000e+00
Epoch 6/10
40/40 [==============================] - ETA: 0s - loss: 7.7649 - instrument_1_loss: 0.7601 - instrument_7_loss: 0.6981 - instrument_41_loss: 0.7116 - instrument_42_loss: 0.7037 - instrument_43_loss: 0.7046 - instrument_44_loss: 0.6974 - instrument_61_loss: 0.6981 - instrument_69_loss: 0.6968 - instrument_71_loss: 0.6986 - instrument_72_loss: 0.6990 - instrument_74_loss: 0.6970 - instrument_1_accuracy: 0.0159 - instrument_1_auc_1: 0.4878 - instrument_7_accuracy: 7.5000e-04 - instrument_7_auc_1: 0.4831 - instrument_41_accuracy: 0.0036 - instrument_41_auc_1: 0.5172 - instrument_42_accuracy: 0.0000e+00 - instrument_42_auc_1: 0.5709 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5191 - instrument_44_accuracy: 2.3437e-04 - instrument_44_auc_1: 0.3375 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.3742 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.5869 - instrument_71_accuracy: 4.6875e-05 - instrument_71_auc_1: 0.5242 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.5000 - instrument_74_accuracy: 5.1562e-04 - instrument_74_auc_1: 0.5644 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_06_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_06_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>40/40 [==============================] - 823s 20s/step - loss: 7.7649 - instrument_1_loss: 0.7601 - instrument_7_loss: 0.6981 - instrument_41_loss: 0.7116 - instrument_42_loss: 0.7037 - instrument_43_loss: 0.7046 - instrument_44_loss: 0.6974 - instrument_61_loss: 0.6981 - instrument_69_loss: 0.6968 - instrument_71_loss: 0.6986 - instrument_72_loss: 0.6990 - instrument_74_loss: 0.6970 - instrument_1_accuracy: 0.0159 - instrument_1_auc_1: 0.4878 - instrument_7_accuracy: 7.5000e-04 - instrument_7_auc_1: 0.4831 - instrument_41_accuracy: 0.0036 - instrument_41_auc_1: 0.5172 - instrument_42_accuracy: 0.0000e+00 - instrument_42_auc_1: 0.5709 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5191 - instrument_44_accuracy: 2.3437e-04 - instrument_44_auc_1: 0.3375 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.3742 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.5869 - instrument_71_accuracy: 4.6875e-05 - instrument_71_auc_1: 0.5242 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.5000 - instrument_74_accuracy: 5.1562e-04 - instrument_74_auc_1: 0.5644 - val_loss: 7.7343 - val_instrument_1_loss: 0.7160 - val_instrument_7_loss: 0.6968 - val_instrument_41_loss: 0.7101 - val_instrument_42_loss: 0.7015 - val_instrument_43_loss: 0.7050 - val_instrument_44_loss: 0.6966 - val_instrument_61_loss: 0.7034 - val_instrument_69_loss: 0.6956 - val_instrument_71_loss: 0.7063 - val_instrument_72_loss: 0.7070 - val_instrument_74_loss: 0.6960 - val_instrument_1_accuracy: 0.0050 - val_instrument_1_auc_1: 0.5094 - val_instrument_7_accuracy: 0.0000e+00 - val_instrument_7_auc_1: 0.0000e+00 - val_instrument_41_accuracy: 0.0000e+00 - val_instrument_41_auc_1: 0.5444 - val_instrument_42_accuracy: 0.0000e+00 - val_instrument_42_auc_1: 0.6109 - val_instrument_43_accuracy: 0.0000e+00 - val_instrument_43_auc_1: 0.4586 - val_instrument_44_accuracy: 0.0000e+00 - val_instrument_44_auc_1: 0.0000e+00 - val_instrument_61_accuracy: 0.0025 - val_instrument_61_auc_1: 0.4560 - val_instrument_69_accuracy: 0.0000e+00 - val_instrument_69_auc_1: 0.0000e+00 - val_instrument_71_accuracy: 0.0012 - val_instrument_71_auc_1: 0.5428 - val_instrument_72_accuracy: 0.0000e+00 - val_instrument_72_auc_1: 0.4793 - val_instrument_74_accuracy: 0.0000e+00 - val_instrument_74_auc_1: 0.0000e+00
Epoch 7/10
40/40 [==============================] - ETA: 0s - loss: 7.7545 - instrument_1_loss: 0.7566 - instrument_7_loss: 0.6973 - instrument_41_loss: 0.7104 - instrument_42_loss: 0.7032 - instrument_43_loss: 0.7040 - instrument_44_loss: 0.6965 - instrument_61_loss: 0.6975 - instrument_69_loss: 0.6961 - instrument_71_loss: 0.6978 - instrument_72_loss: 0.6986 - instrument_74_loss: 0.6965 - instrument_1_accuracy: 0.0227 - instrument_1_auc_1: 0.5040 - instrument_7_accuracy: 9.5313e-04 - instrument_7_auc_1: 0.5582 - instrument_41_accuracy: 0.0034 - instrument_41_auc_1: 0.5480 - instrument_42_accuracy: 1.5625e-05 - instrument_42_auc_1: 0.5572 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5104 - instrument_44_accuracy: 6.0938e-04 - instrument_44_auc_1: 0.4126 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.4421 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.5621 - instrument_71_accuracy: 1.4062e-04 - instrument_71_auc_1: 0.5336 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.5092 - instrument_74_accuracy: 8.2812e-04 - instrument_74_auc_1: 0.5229 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_07_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_07_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>40/40 [==============================] - 1015s 26s/step - loss: 7.7545 - instrument_1_loss: 0.7566 - instrument_7_loss: 0.6973 - instrument_41_loss: 0.7104 - instrument_42_loss: 0.7032 - instrument_43_loss: 0.7040 - instrument_44_loss: 0.6965 - instrument_61_loss: 0.6975 - instrument_69_loss: 0.6961 - instrument_71_loss: 0.6978 - instrument_72_loss: 0.6986 - instrument_74_loss: 0.6965 - instrument_1_accuracy: 0.0227 - instrument_1_auc_1: 0.5040 - instrument_7_accuracy: 9.5313e-04 - instrument_7_auc_1: 0.5582 - instrument_41_accuracy: 0.0034 - instrument_41_auc_1: 0.5480 - instrument_42_accuracy: 1.5625e-05 - instrument_42_auc_1: 0.5572 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5104 - instrument_44_accuracy: 6.0938e-04 - instrument_44_auc_1: 0.4126 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.4421 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.5621 - instrument_71_accuracy: 1.4062e-04 - instrument_71_auc_1: 0.5336 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.5092 - instrument_74_accuracy: 8.2812e-04 - instrument_74_auc_1: 0.5229 - val_loss: 7.7320 - val_instrument_1_loss: 0.7148 - val_instrument_7_loss: 0.6960 - val_instrument_41_loss: 0.7158 - val_instrument_42_loss: 0.7021 - val_instrument_43_loss: 0.7050 - val_instrument_44_loss: 0.6959 - val_instrument_61_loss: 0.6996 - val_instrument_69_loss: 0.6951 - val_instrument_71_loss: 0.7057 - val_instrument_72_loss: 0.7067 - val_instrument_74_loss: 0.6953 - val_instrument_1_accuracy: 0.0056 - val_instrument_1_auc_1: 0.4874 - val_instrument_7_accuracy: 0.0000e+00 - val_instrument_7_auc_1: 0.0000e+00 - val_instrument_41_accuracy: 0.0081 - val_instrument_41_auc_1: 0.5351 - val_instrument_42_accuracy: 0.0000e+00 - val_instrument_42_auc_1: 0.5699 - val_instrument_43_accuracy: 0.0000e+00 - val_instrument_43_auc_1: 0.4698 - val_instrument_44_accuracy: 0.0000e+00 - val_instrument_44_auc_1: 0.0000e+00 - val_instrument_61_accuracy: 0.0000e+00 - val_instrument_61_auc_1: 0.5076 - val_instrument_69_accuracy: 0.0000e+00 - val_instrument_69_auc_1: 0.0000e+00 - val_instrument_71_accuracy: 0.0000e+00 - val_instrument_71_auc_1: 0.5836 - val_instrument_72_accuracy: 0.0000e+00 - val_instrument_72_auc_1: 0.5175 - val_instrument_74_accuracy: 0.0000e+00 - val_instrument_74_auc_1: 0.0000e+00
Epoch 8/10
40/40 [==============================] - ETA: 0s - loss: 7.7481 - instrument_1_loss: 0.7563 - instrument_7_loss: 0.6965 - instrument_41_loss: 0.7097 - instrument_42_loss: 0.7023 - instrument_43_loss: 0.7032 - instrument_44_loss: 0.6959 - instrument_61_loss: 0.6970 - instrument_69_loss: 0.6959 - instrument_71_loss: 0.6972 - instrument_72_loss: 0.6981 - instrument_74_loss: 0.6960 - instrument_1_accuracy: 0.0177 - instrument_1_auc_1: 0.5015 - instrument_7_accuracy: 6.2500e-04 - instrument_7_auc_1: 0.5371 - instrument_41_accuracy: 0.0034 - instrument_41_auc_1: 0.5368 - instrument_42_accuracy: 1.5625e-05 - instrument_42_auc_1: 0.5660 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5082 - instrument_44_accuracy: 8.2812e-04 - instrument_44_auc_1: 0.4698 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.4768 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.5771 - instrument_71_accuracy: 1.8750e-04 - instrument_71_auc_1: 0.5660 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.5181 - instrument_74_accuracy: 8.2812e-04 - instrument_74_auc_1: 0.5266 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_08_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_08_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>40/40 [==============================] - 1063s 27s/step - loss: 7.7481 - instrument_1_loss: 0.7563 - instrument_7_loss: 0.6965 - instrument_41_loss: 0.7097 - instrument_42_loss: 0.7023 - instrument_43_loss: 0.7032 - instrument_44_loss: 0.6959 - instrument_61_loss: 0.6970 - instrument_69_loss: 0.6959 - instrument_71_loss: 0.6972 - instrument_72_loss: 0.6981 - instrument_74_loss: 0.6960 - instrument_1_accuracy: 0.0177 - instrument_1_auc_1: 0.5015 - instrument_7_accuracy: 6.2500e-04 - instrument_7_auc_1: 0.5371 - instrument_41_accuracy: 0.0034 - instrument_41_auc_1: 0.5368 - instrument_42_accuracy: 1.5625e-05 - instrument_42_auc_1: 0.5660 - instrument_43_accuracy: 0.0000e+00 - instrument_43_auc_1: 0.5082 - instrument_44_accuracy: 8.2812e-04 - instrument_44_auc_1: 0.4698 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.4768 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.5771 - instrument_71_accuracy: 1.8750e-04 - instrument_71_auc_1: 0.5660 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.5181 - instrument_74_accuracy: 8.2812e-04 - instrument_74_auc_1: 0.5266 - val_loss: 7.7214 - val_instrument_1_loss: 0.7360 - val_instrument_7_loss: 0.6954 - val_instrument_41_loss: 0.7096 - val_instrument_42_loss: 0.6991 - val_instrument_43_loss: 0.7022 - val_instrument_44_loss: 0.6953 - val_instrument_61_loss: 0.6950 - val_instrument_69_loss: 0.6947 - val_instrument_71_loss: 0.6990 - val_instrument_72_loss: 0.7001 - val_instrument_74_loss: 0.6949 - val_instrument_1_accuracy: 0.0050 - val_instrument_1_auc_1: 0.4999 - val_instrument_7_accuracy: 0.0000e+00 - val_instrument_7_auc_1: 0.0000e+00 - val_instrument_41_accuracy: 0.0025 - val_instrument_41_auc_1: 0.5021 - val_instrument_42_accuracy: 0.0000e+00 - val_instrument_42_auc_1: 0.5982 - val_instrument_43_accuracy: 0.0000e+00 - val_instrument_43_auc_1: 0.5448 - val_instrument_44_accuracy: 0.0000e+00 - val_instrument_44_auc_1: 0.0000e+00 - val_instrument_61_accuracy: 0.0000e+00 - val_instrument_61_auc_1: 0.0000e+00 - val_instrument_69_accuracy: 0.0000e+00 - val_instrument_69_auc_1: 0.0000e+00 - val_instrument_71_accuracy: 0.0000e+00 - val_instrument_71_auc_1: 0.5107 - val_instrument_72_accuracy: 0.0000e+00 - val_instrument_72_auc_1: 0.4850 - val_instrument_74_accuracy: 0.0000e+00 - val_instrument_74_auc_1: 0.0000e+00
Epoch 9/10
40/40 [==============================] - ETA: 0s - loss: 7.7462 - instrument_1_loss: 0.7569 - instrument_7_loss: 0.6962 - instrument_41_loss: 0.7102 - instrument_42_loss: 0.7022 - instrument_43_loss: 0.7034 - instrument_44_loss: 0.6954 - instrument_61_loss: 0.6962 - instrument_69_loss: 0.6956 - instrument_71_loss: 0.6970 - instrument_72_loss: 0.6976 - instrument_74_loss: 0.6956 - instrument_1_accuracy: 0.0090 - instrument_1_auc_1: 0.4916 - instrument_7_accuracy: 8.7500e-04 - instrument_7_auc_1: 0.4746 - instrument_41_accuracy: 0.0042 - instrument_41_auc_1: 0.5434 - instrument_42_accuracy: 1.5625e-05 - instrument_42_auc_1: 0.5592 - instrument_43_accuracy: 1.5625e-05 - instrument_43_auc_1: 0.5093 - instrument_44_accuracy: 0.0019 - instrument_44_auc_1: 0.5424 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.4239 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.5228 - instrument_71_accuracy: 6.8750e-04 - instrument_71_auc_1: 0.5023 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.5054 - instrument_74_accuracy: 0.0000e+00 - instrument_74_auc_1: 0.4956 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_09_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_09_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>40/40 [==============================] - 1070s 27s/step - loss: 7.7462 - instrument_1_loss: 0.7569 - instrument_7_loss: 0.6962 - instrument_41_loss: 0.7102 - instrument_42_loss: 0.7022 - instrument_43_loss: 0.7034 - instrument_44_loss: 0.6954 - instrument_61_loss: 0.6962 - instrument_69_loss: 0.6956 - instrument_71_loss: 0.6970 - instrument_72_loss: 0.6976 - instrument_74_loss: 0.6956 - instrument_1_accuracy: 0.0090 - instrument_1_auc_1: 0.4916 - instrument_7_accuracy: 8.7500e-04 - instrument_7_auc_1: 0.4746 - instrument_41_accuracy: 0.0042 - instrument_41_auc_1: 0.5434 - instrument_42_accuracy: 1.5625e-05 - instrument_42_auc_1: 0.5592 - instrument_43_accuracy: 1.5625e-05 - instrument_43_auc_1: 0.5093 - instrument_44_accuracy: 0.0019 - instrument_44_auc_1: 0.5424 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.4239 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.5228 - instrument_71_accuracy: 6.8750e-04 - instrument_71_auc_1: 0.5023 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.5054 - instrument_74_accuracy: 0.0000e+00 - instrument_74_auc_1: 0.4956 - val_loss: 7.7105 - val_instrument_1_loss: 0.7222 - val_instrument_7_loss: 0.6950 - val_instrument_41_loss: 0.7136 - val_instrument_42_loss: 0.6994 - val_instrument_43_loss: 0.7035 - val_instrument_44_loss: 0.6950 - val_instrument_61_loss: 0.6960 - val_instrument_69_loss: 0.6945 - val_instrument_71_loss: 0.6972 - val_instrument_72_loss: 0.6994 - val_instrument_74_loss: 0.6946 - val_instrument_1_accuracy: 0.0031 - val_instrument_1_auc_1: 0.4976 - val_instrument_7_accuracy: 0.0000e+00 - val_instrument_7_auc_1: 0.0000e+00 - val_instrument_41_accuracy: 0.0106 - val_instrument_41_auc_1: 0.5649 - val_instrument_42_accuracy: 0.0000e+00 - val_instrument_42_auc_1: 0.5388 - val_instrument_43_accuracy: 0.0000e+00 - val_instrument_43_auc_1: 0.5100 - val_instrument_44_accuracy: 0.0000e+00 - val_instrument_44_auc_1: 0.0000e+00 - val_instrument_61_accuracy: 0.0019 - val_instrument_61_auc_1: 0.4717 - val_instrument_69_accuracy: 0.0000e+00 - val_instrument_69_auc_1: 0.0000e+00 - val_instrument_71_accuracy: 0.0000e+00 - val_instrument_71_auc_1: 0.4343 - val_instrument_72_accuracy: 0.0000e+00 - val_instrument_72_auc_1: 0.4660 - val_instrument_74_accuracy: 0.0000e+00 - val_instrument_74_auc_1: 0.0000e+00
Epoch 10/10
40/40 [==============================] - ETA: 0s - loss: 7.7444 - instrument_1_loss: 0.7565 - instrument_7_loss: 0.6958 - instrument_41_loss: 0.7102 - instrument_42_loss: 0.7021 - instrument_43_loss: 0.7035 - instrument_44_loss: 0.6952 - instrument_61_loss: 0.6963 - instrument_69_loss: 0.6953 - instrument_71_loss: 0.6967 - instrument_72_loss: 0.6973 - instrument_74_loss: 0.6954 - instrument_1_accuracy: 0.0147 - instrument_1_auc_1: 0.4936 - instrument_7_accuracy: 8.5937e-04 - instrument_7_auc_1: 0.5001 - instrument_41_accuracy: 0.0035 - instrument_41_auc_1: 0.5259 - instrument_42_accuracy: 1.5625e-05 - instrument_42_auc_1: 0.5330 - instrument_43_accuracy: 3.1250e-05 - instrument_43_auc_1: 0.4885 - instrument_44_accuracy: 0.0027 - instrument_44_auc_1: 0.5748 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.4723 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.5207 - instrument_71_accuracy: 0.0010 - instrument_71_auc_1: 0.4945 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.4725 - instrument_74_accuracy: 0.0000e+00 - instrument_74_auc_1: 0.5151 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_10_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:tensorflow:Assets written to: ../models/classic_direct_conv_to_lstm/20220807_184403_10_classic_direct_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>40/40 [==============================] - 1063s 27s/step - loss: 7.7444 - instrument_1_loss: 0.7565 - instrument_7_loss: 0.6958 - instrument_41_loss: 0.7102 - instrument_42_loss: 0.7021 - instrument_43_loss: 0.7035 - instrument_44_loss: 0.6952 - instrument_61_loss: 0.6963 - instrument_69_loss: 0.6953 - instrument_71_loss: 0.6967 - instrument_72_loss: 0.6973 - instrument_74_loss: 0.6954 - instrument_1_accuracy: 0.0147 - instrument_1_auc_1: 0.4936 - instrument_7_accuracy: 8.5937e-04 - instrument_7_auc_1: 0.5001 - instrument_41_accuracy: 0.0035 - instrument_41_auc_1: 0.5259 - instrument_42_accuracy: 1.5625e-05 - instrument_42_auc_1: 0.5330 - instrument_43_accuracy: 3.1250e-05 - instrument_43_auc_1: 0.4885 - instrument_44_accuracy: 0.0027 - instrument_44_auc_1: 0.5748 - instrument_61_accuracy: 0.0000e+00 - instrument_61_auc_1: 0.4723 - instrument_69_accuracy: 0.0000e+00 - instrument_69_auc_1: 0.5207 - instrument_71_accuracy: 0.0010 - instrument_71_auc_1: 0.4945 - instrument_72_accuracy: 0.0000e+00 - instrument_72_auc_1: 0.4725 - instrument_74_accuracy: 0.0000e+00 - instrument_74_auc_1: 0.5151 - val_loss: 7.7124 - val_instrument_1_loss: 0.7159 - val_instrument_7_loss: 0.6948 - val_instrument_41_loss: 0.7116 - val_instrument_42_loss: 0.6982 - val_instrument_43_loss: 0.7023 - val_instrument_44_loss: 0.6947 - val_instrument_61_loss: 0.6964 - val_instrument_69_loss: 0.6943 - val_instrument_71_loss: 0.7038 - val_instrument_72_loss: 0.7060 - val_instrument_74_loss: 0.6944 - val_instrument_1_accuracy: 0.0044 - val_instrument_1_auc_1: 0.5049 - val_instrument_7_accuracy: 0.0000e+00 - val_instrument_7_auc_1: 0.0000e+00 - val_instrument_41_accuracy: 0.0131 - val_instrument_41_auc_1: 0.5142 - val_instrument_42_accuracy: 0.0000e+00 - val_instrument_42_auc_1: 0.5568 - val_instrument_43_accuracy: 0.0000e+00 - val_instrument_43_auc_1: 0.4590 - val_instrument_44_accuracy: 0.0000e+00 - val_instrument_44_auc_1: 0.0000e+00 - val_instrument_61_accuracy: 0.0000e+00 - val_instrument_61_auc_1: 0.4428 - val_instrument_69_accuracy: 0.0000e+00 - val_instrument_69_auc_1: 0.0000e+00 - val_instrument_71_accuracy: 0.0000e+00 - val_instrument_71_auc_1: 0.4287 - val_instrument_72_accuracy: 0.0000e+00 - val_instrument_72_auc_1: 0.4621 - val_instrument_74_accuracy: 0.0000e+00 - val_instrument_74_auc_1: 0.0000e+00</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>conv_to_lstm_model.save(<span class="st">'../models/new_classic_conv_to_lstm/'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:tensorflow:Assets written to: ../models/new_classic_conv_to_lstm/assets</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:tensorflow:Assets written to: ../models/new_classic_conv_to_lstm/assets</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>save_history(conv_to_lstm_history.history, <span class="st">'../models/new_classic_conv_to_lstm.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>musicnet_eval(conv_to_lstm_model, classic_eval_generator, <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 0s 25ms/step</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="classic_transcription_files/figure-html/cell-43-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Again, same behavior is observed, we have concluded that the input data might be incompatible for our model, further investigation on the input pipeline should be taken.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>